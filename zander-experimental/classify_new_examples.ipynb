{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78188b14-3ee8-4569-8be9-eed2aad0616f",
   "metadata": {},
   "source": [
    "### Using COBERT to classify examples from the big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a9be33-0c5a-4574-bbc1-29bdd9fd9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import string\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AdamW\n",
    ")\n",
    "\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2977f78-1e23-40db-8587-9368a5f61793",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d652481-f565-4f56-a468-c2fb5cfb2c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('new_tweets_only_txt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc53b220-d0d4-4676-8139-5c71725dd1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt = raw_data['text']\n",
    "df_txt.dropna()\n",
    "df_txt = df_txt.astype(str)\n",
    "# df_txt.to_csv('new_tweets_only_txt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0179c478-ea1e-423c-aca2-2072c61c936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['legitimate','misinformation','irrelevant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff9c2a2-0052-4ddc-b8ac-e88ad2ad10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0cd436-1c1f-494d-89b4-13d46b47016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(row):\n",
    "    # Lower case\n",
    "    row = row.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    row = re.sub('http\\S+|www.\\S+', '', row)\n",
    "    \n",
    "    # Remove @mentions\n",
    "    row = re.sub('@[A-Za-z0-9]+', '', row)\n",
    "    \n",
    "    # Remove non-standard characters\n",
    "    row = row.encode(\"ascii\", \"ignore\").decode()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    row = row.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove stop words\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(stop))\n",
    "    row = row.replace(pat, '')\n",
    "    row = row.replace(r'\\s+', ' ')\n",
    "    \n",
    "    # Remove extraneous whitespace\n",
    "    row = row.strip()\n",
    "    \n",
    "    # Lemmatization\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    w_tokenization = nltk.word_tokenize(row)\n",
    "    final = \"\"\n",
    "    for w in w_tokenization:\n",
    "        final = final + \" \" + wordnet_lemmatizer.lemmatize(w)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d403c2c-4280-4b25-a89f-877f99e21315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_txt)\n",
    "clean_txt = df_txt.copy().apply(clean_text)\n",
    "df['clean_text'] = clean_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55bf91a3-2c18-4707-97cb-0b07b2e2e9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31439</th>\n",
       "      <td>This report focuses on Canada's psychological ...</td>\n",
       "      <td>this report focus on canada psychological man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31440</th>\n",
       "      <td>@Shane_BSer @ongreenthings @ajamubaraka Right,...</td>\n",
       "      <td>bser right vaccination alone isnt an actual s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31441</th>\n",
       "      <td>@CDCgov you can just say Women. y'know, since ...</td>\n",
       "      <td>you can just say woman yknow since no one els...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31442</th>\n",
       "      <td>@DailyBlessFarm @S_S_Daisy @tatereeves @newway...</td>\n",
       "      <td>sdaisy you got that right i jumped the gun an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31443</th>\n",
       "      <td>@ClayTravis What we know is the vaccine does n...</td>\n",
       "      <td>what we know is the vaccine doe not actually ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "31439  This report focuses on Canada's psychological ...   \n",
       "31440  @Shane_BSer @ongreenthings @ajamubaraka Right,...   \n",
       "31441  @CDCgov you can just say Women. y'know, since ...   \n",
       "31442  @DailyBlessFarm @S_S_Daisy @tatereeves @newway...   \n",
       "31443  @ClayTravis What we know is the vaccine does n...   \n",
       "\n",
       "                                              clean_text  \n",
       "31439   this report focus on canada psychological man...  \n",
       "31440   bser right vaccination alone isnt an actual s...  \n",
       "31441   you can just say woman yknow since no one els...  \n",
       "31442   sdaisy you got that right i jumped the gun an...  \n",
       "31443   what we know is the vaccine doe not actually ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9215e902-86cd-459b-8e29-d8e3a575b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'fifth_miscov19-covid-twitter-bert-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(PATH, local_files_only=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(PATH, num_labels=len(target_names), local_files_only=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65fc7f31-6fa6-4867-a694-867a925094c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    # apply preprocessing to text\n",
    "    inputs = clean_text(text)\n",
    "    # prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(inputs, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    # perform inference to our model\n",
    "    outputs = model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    return target_names[probs.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56bf3907-a4a4-4532-827e-6d6244f9db28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = df.iloc[::15,:]\n",
    "len(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50bd8f90-f0ab-4686-943c-365edc4f37f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2794/3778933775.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small['COBERT_classification'] = df['clean_text'].copy().apply(get_prediction)\n"
     ]
    }
   ],
   "source": [
    "small['COBERT_classification'] = df['clean_text'].copy().apply(get_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d691725d-d75d-452e-ac7a-c8a4e76b6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "small.to_csv(\"classified_2097.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd6096-7478-4e52-bb67-7654f143c38a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zander_exp",
   "language": "python",
   "name": "zander_exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

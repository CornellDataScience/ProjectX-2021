{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demo.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pY-7ENc4vMfM","executionInfo":{"status":"ok","timestamp":1638917598332,"user_tz":300,"elapsed":18578,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}},"outputId":"ba35bbe6-f463-4775-f957-9dbe3d9f7f10"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"N7VUCs7heyc3"},"source":["**Install dependencies**"]},{"cell_type":"code","metadata":{"id":"MHPjys9hvVn9","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1638917660182,"user_tz":300,"elapsed":48357,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}},"outputId":"2fc906ec-8611-4b67-d6f2-9241baff174b"},"source":["!pip install pytorch-pretrained-bert pytorch-nlp\n","\n","!pip install sentence-transformers\n","\n","!pip install keras\n","\n","!pip install awscli --ignore-installed six\n","\n","!pip install spacy ftfy==4.4.3\n","!python -m spacy download en"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-pretrained-bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 123 kB 5.2 MB/s \n","\u001b[?25hCollecting pytorch-nlp\n","  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.10.0+cu111)\n","Collecting boto3\n","  Downloading boto3-1.20.21-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 41.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.10.0.2)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.24.0,>=1.23.21\n","  Downloading botocore-1.23.21-py3-none-any.whl (8.4 MB)\n","\u001b[K     |████████████████████████████████| 8.4 MB 35.5 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.21->boto3->pytorch-pretrained-bert) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 22.9 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.21->boto3->pytorch-pretrained-bert) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 49.3 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.20.21 botocore-1.23.21 jmespath-0.10.0 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.0 urllib3-1.25.11\n","Collecting sentence-transformers\n","  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 3.5 MB/s \n","\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 11.3 MB/s \n","\u001b[?25hCollecting tokenizers>=0.10.3\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 30.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 40.6 MB/s \n","\u001b[?25hCollecting huggingface-hub\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 523 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 48.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 37.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.0.0)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=82539783d35ac8437ee6f552d1cf20842479e035f173d1bda302afc8b07c9bba\n","  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n","Successfully built sentence-transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.12.5\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n","Collecting awscli\n","  Downloading awscli-1.22.21-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 5.1 MB/s \n","\u001b[?25hCollecting six\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting colorama<0.4.4,>=0.2.5\n","  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n","Collecting rsa<4.8,>=3.1.2\n","  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Using cached s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","Collecting PyYAML<5.5,>=3.10\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 42.8 MB/s \n","\u001b[?25hCollecting docutils<0.16,>=0.10\n","  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n","\u001b[K     |████████████████████████████████| 547 kB 44.9 MB/s \n","\u001b[?25hCollecting botocore==1.23.21\n","  Using cached botocore-1.23.21-py3-none-any.whl (8.4 MB)\n","Collecting urllib3<1.27,>=1.25.4\n","  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting python-dateutil<3.0.0,>=2.1\n","  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n","\u001b[K     |████████████████████████████████| 247 kB 44.3 MB/s \n","\u001b[?25hCollecting pyasn1>=0.1.3\n","  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 5.7 MB/s \n","\u001b[?25hInstalling collected packages: six, urllib3, python-dateutil, jmespath, pyasn1, botocore, s3transfer, rsa, PyYAML, docutils, colorama, awscli\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-6.0 awscli-1.22.21 botocore-1.23.21 colorama-0.4.3 docutils-0.17.1 jmespath-0.10.0 pyasn1-0.4.8 python-dateutil-2.8.2 rsa-4.8 s3transfer-0.5.0 six-1.16.0 urllib3-1.26.7\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dateutil","six"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n","Collecting ftfy==4.4.3\n","  Downloading ftfy-4.4.3.tar.gz (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 3.1 MB/s \n","\u001b[?25hRequirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (from ftfy==4.4.3) (1.0.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy==4.4.3) (0.2.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from html5lib->ftfy==4.4.3) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib->ftfy==4.4.3) (0.5.1)\n","Building wheels for collected packages: ftfy\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-4.4.3-py3-none-any.whl size=41082 sha256=76cd57c20bd699a3a626c4889503a8a95c3b7c202d813a926a30cc2a5367a987\n","  Stored in directory: /root/.cache/pip/wheels/b0/66/08/c65b9e8a3b674f10739790db0cbbc846afaa20a3f80f0b9e42\n","Successfully built ftfy\n","Installing collected packages: urllib3, ftfy\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.7\n","    Uninstalling urllib3-1.26.7:\n","      Successfully uninstalled urllib3-1.26.7\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","awscli 1.22.21 requires docutils<0.16,>=0.10, but you have docutils 0.17.1 which is incompatible.\n","awscli 1.22.21 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n","awscli 1.22.21 requires rsa<4.8,>=3.1.2, but you have rsa 4.8 which is incompatible.\u001b[0m\n","Successfully installed ftfy-4.4.3 urllib3-1.25.11\n","Collecting en_core_web_sm==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n","\u001b[K     |████████████████████████████████| 12.0 MB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"]}]},{"cell_type":"code","metadata":{"id":"mStW5zpKvcO2","executionInfo":{"status":"ok","timestamp":1638917668817,"user_tz":300,"elapsed":8641,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}}},"source":["import torch\n","import numpy as np\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig, OpenAIGPTModel, OpenAIGPTTokenizer\n","from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n","from transformers import pipeline\n","\n","from keras.preprocessing.sequence import pad_sequences"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O2TN6clifA9k"},"source":["**Load the pre-trained model weights from Google Colab directory**"]},{"cell_type":"code","metadata":{"id":"9cDhSK-Avryt","executionInfo":{"status":"ok","timestamp":1638917668818,"user_tz":300,"elapsed":5,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}}},"source":["def load_model(file_str): # path_to_model -> pytorch model\n","    # Load model file and return the model\n","    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n","    model.load_state_dict(torch.load(file_str))\n","    model.eval()\n","    return model"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kqIk4bhKfGJv"},"source":["**Map the predicted class to the corresponding label**"]},{"cell_type":"code","metadata":{"id":"y5XaorT7Cy9Y","executionInfo":{"status":"ok","timestamp":1638917668819,"user_tz":300,"elapsed":4,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}}},"source":["def map(prediction):\n","  return {2 : \"irrelevant\", 1 : \"misinformation\", 0 : \"legitimate information\"}[prediction]"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mblUddoQfgw6"},"source":["**Pass in sample text to classify**"]},{"cell_type":"code","metadata":{"id":"dYHJR2BUvxQS","executionInfo":{"status":"ok","timestamp":1638917669401,"user_tz":300,"elapsed":6,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}}},"source":["def inference(tweet_txt, model): # tweet_string -> label_string\n","  tweet_txt = np.array([tweet_txt])\n","  test_sentence = [\"[CLS] \" + str(text) + \" [SEP]\" for text in tweet_txt]\n","  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","  tokenized_text = [tokenizer.tokenize(text) for text in test_sentence]\n","\n","  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]\n","  input_ids = pad_sequences(input_ids, maxlen=90, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","  attention_masks = []\n","  test_inputs = torch.tensor(input_ids, dtype = torch.long)\n","\n","  for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","  \n","  prediction = []\n","  test_masks = torch.tensor(attention_masks, dtype = torch.long)\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(test_inputs, token_type_ids=None, attention_mask=test_masks)\n","\n","  logits = logits.detach().cpu().numpy()\n","  prediction.append(logits)\n","\n","  flat_predictions = [item for sublist in prediction for item in sublist]\n","  flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","  label_predictions = []\n","  for pred in flat_predictions:\n","    label_predictions.append(map(pred))\n","\n","  return label_predictions[0]"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hx4iWsnSgXLH"},"source":["Current attempt to pipeline our model and a fake news detection task"]},{"cell_type":"code","metadata":{"id":"-_Rq3KH-7WjN"},"source":["from transformers import Pipeline\n","\n","class FakeNewsClassificationPipeline(Pipeline):\n","    def _sanitize_parameters(self, **kwargs):\n","      preprocess_kwargs = {}\n","      if \"fake-news-classification\" in kwargs:\n","          preprocess_kwargs[\"fake-news-classification\"] = kwargs[\"fake-news-classification\"]\n","      return preprocess_kwargs, {}, {}\n","\n","    def preprocess(self, inputs, maybe_arg=1):\n","      test_sentence = [\"[CLS] \" + str(text) + \" [SEP]\" for text in inputs]\n","      tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","      tokenized_text = [tokenizer.tokenize(text) for text in test_sentence]\n","\n","      input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","      input_ids = pad_sequences(input_ids, maxlen=90, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","      attention_masks = []\n","      model_input = torch.tensor(input_ids, dtype = torch.long)\n","      return {\"model_input\": model_input}\n","\n","    def _forward(self, model_inputs):\n","      # model_inputs == {\"model_input\": model_input}\n","      oututs = self.model(**model_inputs)\n","      # Maybe {\"logits\": Tensor(...)}\n","      return outputs\n","\n","    def postprocess(self, model_outputs):\n","      best_class = model_outputs[\"logits\"].softmax(-1)\n","      return best_class\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"98fS1ik81RPJ"},"source":["def classify(tweet_txt, model, tokenizer):\n","  classification = FakeNewsClassificationPipeline(\"fake-news-classification\", model = model, tokenizer = tokenizer)\n","  return classification(tweet_txt)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XAESmQA9gcdg"},"source":["Loading in our pre-trained model from bert.bin"]},{"cell_type":"code","metadata":{"id":"6eXwH-8WvfxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638917708416,"user_tz":300,"elapsed":39019,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}},"outputId":"38fedebc-8e99-4da5-86bb-cf444b682a6e"},"source":["# edward_dir ='/content/drive/My Drive/CornellUniversity/CDS/ProjectX/Subprojects/bert.bin'\n","# melinda_dir = 'drive/MyDrive/ProjectX/Subprojects/bert.bin'\n","dir ='/content/drive/My Drive/CDS/ProjectX/Subprojects/bert.bin'\n","model = load_model(dir)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 407873900/407873900 [00:11<00:00, 34133495.99B/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"ffKUqm2GhFJW"},"source":["**Sample tweets that were not in the training, validation, or testing data sets**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpxcJPHJAtSa","executionInfo":{"status":"ok","timestamp":1638917709402,"user_tz":300,"elapsed":1006,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}},"outputId":"cc3d7334-379b-4b97-8dcc-dd2b67f5b019"},"source":["tweet_example1 = \"First stats for omicron in Israel: protection for vaccinated similar to Delta, twice as dangerous for unvaccinated\"\n","print(inference(tweet_example1, model))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 231508/231508 [00:00<00:00, 2097129.35B/s]\n"]},{"output_type":"stream","name":"stdout","text":["misinformation\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylA4fj5XGJSc","executionInfo":{"status":"ok","timestamp":1638917709965,"user_tz":300,"elapsed":565,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}},"outputId":"0107987d-3b22-4b38-ad7a-edcf631a470c"},"source":["tweet_example2 = \"DP Dough is the best restaurant in collegetown\"\n","print(inference(tweet_example2, model))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["irrelevant\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXJgSdIYGcZP","executionInfo":{"status":"ok","timestamp":1638917710493,"user_tz":300,"elapsed":531,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}},"outputId":"13945ba6-a499-41c1-c465-a7a4a5355f77"},"source":["tweet_example3 = \"Omicron Unlikely to Cause Severe Illness in Vaccinated People, BioNTech Founder Says\"\n","print(inference(tweet_example3, model))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["legitimate information\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_My9bdiQGvgS","executionInfo":{"status":"ok","timestamp":1638917711166,"user_tz":300,"elapsed":676,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}},"outputId":"c1e978ab-352b-4862-b05d-416d9b09b281"},"source":["tweet_example4 = \"Vaccines cause autism\"\n","print(inference(tweet_example4, model))"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["misinformation\n"]}]},{"cell_type":"markdown","metadata":{"id":"_qiqTOPeg8-i"},"source":["**Try your own input!**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"p1TMzELQf9aA","executionInfo":{"status":"ok","timestamp":1638919281913,"user_tz":300,"elapsed":807,"user":{"displayName":"Kaitlyn Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06417935776921456430"}},"outputId":"48c819ea-4fd1-4039-9dc8-2928a3e6b589"},"source":["tweet_example = \"Vaccines are the best way to end a pandemic\" #@param {type:\"string\"}\n","print(inference(tweet_example, model))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["misinformation\n"]}]}]}